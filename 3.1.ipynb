{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "class DummyClassifier(BaseEstimator) :\n",
    "\n",
    "    def fit(self, x, y=None) :\n",
    "        pass\n",
    "\n",
    "    def predict(self, x) :\n",
    "        pred = np.zeros( (x.shape[0], 1))\n",
    "        for i in range(x.shape[0]) :\n",
    "            if x['Sex'].iloc[i] == 1 :\n",
    "                pred[i] = 0\n",
    "            else :\n",
    "                pred[i] = 1\n",
    "        return pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# Modify code for not defined values\n",
    "def fill_na(df) :\n",
    "    df['Age'].fillna(df['Age'].mean(), inplace=True)\n",
    "    df['Cabin'].fillna('N', inplace=True)\n",
    "    df['Embarked'].fillna('N', inplace=True)\n",
    "    df['Fare'].fillna(0, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Delete code that is unnecessary code\n",
    "def drop_features(df) :\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket'], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Execute label encoding\n",
    "def format_features(df) :\n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features = ['Cabin', 'Sex', 'Embarked']\n",
    "    for feature in features :\n",
    "        le = LabelEncoder()\n",
    "        le = le.fit(df[feature])\n",
    "        df[feature] = le.transform(df[feature])\n",
    "    return df\n",
    "\n",
    "# Call the function\n",
    "def transform_features(df) :\n",
    "    df = fill_na(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score : 0.8156424581005587\n"
     ]
    }
   ],
   "source": [
    "# Data reload from raw data to meta data\n",
    "titan_df = pd.read_csv('../1ìž¥/titanic/train.csv')\n",
    "y_titan_df = titan_df['Survived']\n",
    "x_titan_df = titan_df.drop('Survived', axis=1)\n",
    "x_titan_df = transform_features(x_titan_df)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_titan_df, y_titan_df, test_size=0.2)\n",
    "\n",
    "clf = DummyClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "predictions = clf.predict(x_test)\n",
    "print('Accuracy score : {0}'.format(accuracy_score(y_test, predictions)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. ...  0.  0.  0.]\n",
      " [ 0.  0.  0. ... 10.  0.  0.]\n",
      " [ 0.  0.  0. ... 16.  9.  0.]\n",
      " ...\n",
      " [ 0.  0.  1. ...  6.  0.  0.]\n",
      " [ 0.  0.  2. ... 12.  0.  0.]\n",
      " [ 0.  0. 10. ... 12.  1.  0.]]\n",
      "[0 1 2 ... 8 9 8]\n",
      "['pixel_0_0', 'pixel_0_1', 'pixel_0_2', 'pixel_0_3', 'pixel_0_4', 'pixel_0_5', 'pixel_0_6', 'pixel_0_7', 'pixel_1_0', 'pixel_1_1', 'pixel_1_2', 'pixel_1_3', 'pixel_1_4', 'pixel_1_5', 'pixel_1_6', 'pixel_1_7', 'pixel_2_0', 'pixel_2_1', 'pixel_2_2', 'pixel_2_3', 'pixel_2_4', 'pixel_2_5', 'pixel_2_6', 'pixel_2_7', 'pixel_3_0', 'pixel_3_1', 'pixel_3_2', 'pixel_3_3', 'pixel_3_4', 'pixel_3_5', 'pixel_3_6', 'pixel_3_7', 'pixel_4_0', 'pixel_4_1', 'pixel_4_2', 'pixel_4_3', 'pixel_4_4', 'pixel_4_5', 'pixel_4_6', 'pixel_4_7', 'pixel_5_0', 'pixel_5_1', 'pixel_5_2', 'pixel_5_3', 'pixel_5_4', 'pixel_5_5', 'pixel_5_6', 'pixel_5_7', 'pixel_6_0', 'pixel_6_1', 'pixel_6_2', 'pixel_6_3', 'pixel_6_4', 'pixel_6_5', 'pixel_6_6', 'pixel_6_7', 'pixel_7_0', 'pixel_7_1', 'pixel_7_2', 'pixel_7_3', 'pixel_7_4', 'pixel_7_5', 'pixel_7_6', 'pixel_7_7']\n"
     ]
    },
    {
     "data": {
      "text/plain": "array([False, False, False, ..., False, False, False])"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FakeClassifier(BaseEstimator) :\n",
    "\n",
    "    def fit(self, x, y) :\n",
    "        pass\n",
    "\n",
    "    def predict(self, x) :\n",
    "        return np.zeros( (len(x) ,1 ) , dtype=bool )\n",
    "\n",
    "digits = load_digits()\n",
    "print(digits.data)\n",
    "print(digits.target)\n",
    "print(digits.feature_names)\n",
    "\n",
    "# Find image that is number 7\n",
    "digits.target == 7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(450,)\n",
      "0    410\n",
      "1     40\n",
      "dtype: int64\n",
      "Accuracy score : 0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "# Change type from boolean to integer\n",
    "y = (digits.target == 7).astype(int)\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.data, y)\n",
    "\n",
    "print(y_test.shape)\n",
    "print(pd.Series(y_test).value_counts())\n",
    "\n",
    "clf = FakeClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "\n",
    "print('Accuracy score : {0}'.format(accuracy_score(y_test, pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[410,   0],\n       [ 40,   0]], dtype=int64)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion matrix (FN, TN, FP, TP)\n",
    "confusion_matrix(y_test, pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision :  0.0\n",
      "Recall :  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\intellij_data\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall\n",
    "print('Precision : ', precision_score(y_test, pred))\n",
    "print('Recall : ', recall_score(y_test, pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "def get_clf_eval(y_test, pred) :\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy = accuracy_score(y_test, pred)\n",
    "    precision = precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    print(confusion)\n",
    "    print('Accuracy : {0}, Precision : {1} , Recall : {2}'.format(accuracy, precision, recall))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[87 23]\n",
      " [16 53]]\n",
      "Accuracy : 0.7821229050279329, Precision : 0.6973684210526315 , Recall : 0.7681159420289855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\intellij_data\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_titan_df, y_titan_df, test_size=0.2)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(x_train, y_train)\n",
    "pred = clf.predict(x_test)\n",
    "get_clf_eval(y_test, pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred proba shape :  (179, 2)\n",
      "[[0.20732631 0.79267369]\n",
      " [0.89201768 0.10798232]\n",
      " [0.91374176 0.08625824]]\n",
      "pred shape :  (179,)\n",
      "[[0.20732631 0.79267369 1.        ]\n",
      " [0.89201768 0.10798232 0.        ]\n",
      " [0.91374176 0.08625824 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Precision / Recall : Trade-off\n",
    "pred_prob = clf.predict_proba(x_test)\n",
    "pred = clf.predict(x_test)\n",
    "print('pred proba shape : ', pred_prob.shape)\n",
    "# [ 0 (negative ratio) 1 (positive ratio) ]\n",
    "print(pred_prob[:3])\n",
    "print('pred shape : ', pred.shape)\n",
    "\n",
    "# Combine the two arrays into columns\n",
    "pred_prob_result = np.concatenate([pred_prob, pred.reshape(-1,1)], axis=1)\n",
    "print(pred_prob_result[:3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "[[87 23]\n",
      " [16 53]]\n",
      "Accuracy : 0.7821229050279329, Precision : 0.6973684210526315 , Recall : 0.7681159420289855\n"
     ]
    }
   ],
   "source": [
    "# Binarizer\n",
    "\n",
    "x = [[1, -1, 2],\n",
    "     [2, 0, 0],\n",
    "     [0, 1.1, 1.2]]\n",
    "\n",
    "# Threshold returns 0 if equal to or less than the reference value and 1 if greater\n",
    "binarizer = Binarizer(threshold=1.1)\n",
    "print(binarizer.fit_transform(x))\n",
    "\n",
    "# Standard threshold is 0.5\n",
    "custom_threshold = 0.5\n",
    "pred_prob_nd = pred_prob[:, 1].reshape(-1, 1)\n",
    "binarizer = Binarizer(threshold=custom_threshold).fit(pred_prob_nd)\n",
    "custom_pred = binarizer.transform(pred_prob_nd)\n",
    "\n",
    "get_clf_eval(y_test, custom_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold :  0.4\n",
      "[[84 26]\n",
      " [15 54]]\n",
      "Accuracy : 0.770949720670391, Precision : 0.675 , Recall : 0.782608695652174\n",
      "Threshold :  0.45\n",
      "[[84 26]\n",
      " [15 54]]\n",
      "Accuracy : 0.770949720670391, Precision : 0.675 , Recall : 0.782608695652174\n",
      "Threshold :  0.5\n",
      "[[87 23]\n",
      " [16 53]]\n",
      "Accuracy : 0.7821229050279329, Precision : 0.6973684210526315 , Recall : 0.7681159420289855\n",
      "Threshold :  0.55\n",
      "[[90 20]\n",
      " [16 53]]\n",
      "Accuracy : 0.7988826815642458, Precision : 0.726027397260274 , Recall : 0.7681159420289855\n",
      "Threshold :  0.6\n",
      "[[94 16]\n",
      " [20 49]]\n",
      "Accuracy : 0.7988826815642458, Precision : 0.7538461538461538 , Recall : 0.7101449275362319\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.4, 0.45, 0.5, 0.55, 0.6]\n",
    "\n",
    "def get_eval_by_threshold(y_test, pred, thresholds) :\n",
    "    for custom_threshold in thresholds :\n",
    "        binarizer = Binarizer(threshold=custom_threshold).fit(pred)\n",
    "        custom_pred = binarizer.transform(pred)\n",
    "        print('Threshold : ', custom_threshold)\n",
    "        get_clf_eval(y_test, custom_pred)\n",
    "\n",
    "get_eval_by_threshold(y_test, pred_prob[:, 1].reshape(-1, 1), thresholds)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162,)\n",
      "(163,)\n",
      "(163,)\n",
      "[0.07476971 0.07479386 0.07566252 0.08131544 0.08625824]\n",
      "[0.40350877 0.4        0.40236686 0.4047619  0.40718563]\n",
      "[1.         0.98550725 0.98550725 0.98550725 0.98550725]\n"
     ]
    }
   ],
   "source": [
    "pred_prob_class = clf.predict_proba(x_test)[:, 1]\n",
    "# print(pred_prob_class.reshape(-1,1))\n",
    "\n",
    "precision, recalls, thresholds = precision_recall_curve(y_test, pred_prob_class)\n",
    "print(thresholds.shape)\n",
    "print(precision.shape)\n",
    "print(recalls.shape)\n",
    "\n",
    "print(thresholds[:5])\n",
    "print(precision[:5])\n",
    "print(recalls[:5])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}